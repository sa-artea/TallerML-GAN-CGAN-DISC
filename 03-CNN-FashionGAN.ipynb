{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5004306a",
   "metadata": {},
   "source": [
    "# GAN: REDES GENERATIVAS ADVERSARIALES\n",
    "Utilice el conjunto de datos Fashion-MNIST para construir una red generativa adversarial (GAN) que genere imágenes de productos de moda. Para la construcción del modelo utilice los esquemas que se describen a continuación y compare los resultados:\n",
    "\n",
    "1. Definir un generador basado en una red neuronal convolucional (practica 1).\n",
    "2. Definir un discriminador basado en una red neuronal convolucional (practica 2).\n",
    "3. Definir un modelo GAN que conecte el generador y el discriminador (practica 3).\n",
    "4. Entrenar el modelo GAN con el conjunto de datos Fashion-MNIST.\n",
    "5. Generar imágenes de productos de moda con el modelo GAN.\n",
    "\n",
    "Compruebe con ejemplos que el modelo es capaz de generar imágenes de productos de moda.\n",
    "\n",
    "## OBJETIVO\n",
    "Aplicar el proceso de aprendizaje para reconstruir imágenes de productos utilizando redes neuronales convolucionales profundas.\n",
    "\n",
    "## DATOS\n",
    "Incluidos en Keras.\n",
    "También, existe otra fuente equivalente que se consigue en el siguiente URL https://www.kaggle.com/zalando-research/fashionmnist donde hay un resumen de estos datos en el archivo CVS y XLSX.\n",
    "\n",
    "la clasificación para el aprendizaje supervisado es:\n",
    "\n",
    "    Label \tClass\n",
    "    0 \t \tT-shirt/top\n",
    "    1 \t \tTrouser\n",
    "    2 \t \tPullover\n",
    "    3 \t \tDress\n",
    "    4 \t \tCoat\n",
    "    5 \t \tSandal\n",
    "    6 \t \tShirt\n",
    "    7 \t \tSneaker\n",
    "    8 \t \tBag\n",
    "    9 \t \tAnkle boot\n",
    "\n",
    "**Importante: Lea los comentarios y apuntes del Notebook para tener claridad de los pasos.**\n",
    "\n",
    "### Consideraciones\n",
    "- Utilice sólo los conjuntos de datos indicado.\n",
    "- El frameworks a utilizar es TensorFlow, Keras con Jupyter Notebbooks.\n",
    "\n",
    "### Enlaces de interés\n",
    "- documentación Keras, URL: https://keras.io/models/sequential/\n",
    "- documentación TensorFlow, URL: https://www.tensorflow.org/versions\n",
    "- Tutorial CNN basico, URL: https://www.kaggle.com/nhlr21/deep-keras-cnn-tutorial/notebook\n",
    "- Tutorial GAN, URL: https://www.kaggle.com/insaff/img2img-gan-using-keras\n",
    "- Video tutorial GAN, URL: https://www.youtube.com/watch?v=AALBGpLbj6Q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730dfd22",
   "metadata": {},
   "source": [
    "## Importando Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fdc7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando dependencias de trabajo\n",
    "# importando librerias basicas\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# importando modulos de analisis de datos, ML y graficas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "# importando dependencias para tensorflow\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# importando para sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# importando para modelos de keras\n",
    "from keras.models import Model\n",
    "# importando capas de keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import UpSampling2D\n",
    "\n",
    "# funciones de optimizacion y perdida\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "# funciones para callbacks\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009622e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 revisando la presencia de la GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502947cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurando la memoria de la GPU y evitando el consumo total de la memoria\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f708a",
   "metadata": {},
   "source": [
    "## Funciones Utiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083c64d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que recibe una lista numpy y recupera la forma de cada elemento, devuelve una lista con formas\n",
    "def get_shape(data):\n",
    "    # respuesta de la funcion\n",
    "    ans = list()\n",
    "\n",
    "    for d in data:\n",
    "        sp = d.shape\n",
    "        ans.append(sp)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc0f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que transforma el entero de la clase a la palabra de la etiqueta, devuelve una lista de etiquetas\n",
    "def class2label(data, labels):\n",
    "    # respuesta de la funcion\n",
    "    ans = list()\n",
    "\n",
    "    for d in data:\n",
    "        d = int(d)\n",
    "        l = str(labels[d])\n",
    "        ans.append(l)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d75648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que estandariza los datos en numpy de acuerdo a un valor min & max, devuelve un arreglo np flotante\n",
    "def std_data(data, minv, maxv):\n",
    "    rangev = maxv - minv\n",
    "    ans = data.astype(\"float32\")/float(rangev)\n",
    "    # respuesta de la funcion\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ed4e0",
   "metadata": {},
   "source": [
    "## Cargar y Preparar los Datos\n",
    "\n",
    "Los pasos de esta sección son:\n",
    "\n",
    "1. Leer los datos desde MNIST.\n",
    "2. Formatear los datos para que los acepte el DataFrame de Pandas.\n",
    "2. Crear el DataFrame de Pandas con un esquema propio.\n",
    "2. Formatear los datos MNIST para pobrar el DataFrame de pandas.\n",
    "3. Revisar que todo este como debería estar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ed2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de nombres de las clasificaciones\n",
    "label_names=[     # label number\n",
    "    \"T-shirt/top\",      # 0\n",
    "    \"Trouser\",          # 1\n",
    "    \"Pullover\",         # 2\n",
    "    \"Dress\",            # 3\n",
    "    \"Coat\",             # 4\n",
    "    \"Sandal\",           # 5\n",
    "    \"Shirt\",            # 6\n",
    "    \"Sneaker\",          # 7\n",
    "    \"Bag\",              # 8\n",
    "    \"Ankle boot\"        # 9\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ade325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# se carga el archivo de datos de trabajo por medio de Keras\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd37c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombres de columnas para el dataframe de pandas\n",
    "col_names = [           # nombre de columna DF\n",
    "    \"img_data\",         # datos de la imagen\n",
    "    \"img_shape\",        # forma de la imagen\n",
    "    \"class\",            # clase de la imagen, de 0 a 9\n",
    "    \"label\",            # nombre de la clase\n",
    "    \"std_img_data\",     # datos de la imagen estandarizados\n",
    "    \"cat_labels\"        # etiquetas categoricas de la clase\n",
    "]\n",
    "# \"ReshapeData\", \"Label\", \"Class\", \"DataSize\", \"ReshapeSize\", \"ResKeras\", \"ScoreKeras\"]\n",
    "# creando dataframe con columnas\n",
    "fashion_df = pd.DataFrame(columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrando datos de mnist\n",
    "img_data = np.concatenate((x_train, x_test), axis = 0)\n",
    "class_data = np.concatenate((y_train, y_test), axis = 0)\n",
    "# recuperando forma de imagenes\n",
    "img_shape = get_shape(img_data)\n",
    "# recuperando etiquetas de las clases\n",
    "labels = class2label(class_data, label_names)\n",
    "# estandarizar los datos de la imagen\n",
    "std_img_data = std_data(img_data, 0, 255)\n",
    "# categorizando las clases a aprender\n",
    "cat_labels = to_categorical(class_data, len(label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f2f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambio de formato para utilizar el dataframe\n",
    "img_data = img_data.tolist()\n",
    "std_img_data = std_img_data.tolist()\n",
    "cat_labels = cat_labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7ecc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definir arreglo basico de datos\n",
    "data_lt = (\n",
    "    img_data,       # datos de la imagen   0\n",
    "    img_shape,      # forma de la imagen   1\n",
    "    class_data,     # clase de la imagen   2\n",
    "    labels,         # nombre de la clase   3\n",
    "    std_img_data,   # datos de la imagen estandarizados 4\n",
    "    cat_labels,     # etiquetas categoricas de la clase 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040864ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poblamdo las columnas del dataframe\n",
    "for col, data in zip(col_names, data_lt):\n",
    "    fashion_df[col] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0462bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# informacion del dataframe\n",
    "fashion_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d647a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprime el encabezado del dataframe\n",
    "fashion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libero memoria\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5f608e",
   "metadata": {},
   "source": [
    "## Revisando los Datos\n",
    "Es importante revisar los datos para saber que se esta trabajando con ellos. En esta sección se revisa la forma de los datos, se visualizan algunas imágenes y se revisa la distribución de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef0481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pruebo imagenes del dataset\n",
    "# imagen de 5x5 subplots con tamaño de 10x10\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.figure(figsize=(10,10))\n",
    "# recorriendo las imagenes\n",
    "for i in range(25):\n",
    "    # creando subplots\n",
    "    plt.subplot(5,5,i+1)\n",
    "    # xticks y yticks desactivados\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    # tomo la imagen de la columna de datos de la imagen\n",
    "    # el mapa de colores es viridis de matplotlib\n",
    "    # otras opciones son: \"plasma\", \"viridis\", \"BuPu\", \"hsv\", \"Spectral\"\n",
    "    plt.imshow(fashion_df[\"img_data\"][i], cmap=plt.cm.Spectral)\n",
    "    # tomo el nombre de la clase de la columna de etiquetas\n",
    "    plt.xlabel(fashion_df[\"label\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0233099",
   "metadata": {},
   "source": [
    "## Preprocesar los Datos\n",
    "\n",
    "Los pasos de esta sección son:\n",
    "\n",
    "1. Revisar que los datos están bien.\n",
    "2. Elegir la características o propiedades de aprendizaje.\n",
    "3. Elegir la variable objetivo del aprendizaje.\n",
    "4. Dividir el conjunto de datos entre las poblaciones de entrenamiento y pruebas.\n",
    "5. Formatear los datos de aprendizaje y objetivo acorde a la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df19f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chequeo la distribucion de datos\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.figure(figsize=(20, 8))\n",
    "sns.histplot(fashion_df[col_names[3]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b55f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionando caracteristicas de aprendizaje y variables objetivo\n",
    "# recuperando la forma de las imagenes basado en el primer elemento de la lista\n",
    "\n",
    "# recuperando los valores y ajustando el tensor para la CNN\n",
    "A = fashion_df[col_names[4]]\n",
    "# recuperando los valores de la cateogoria\n",
    "b = fashion_df[col_names[5]].values\n",
    "\n",
    "# fortateo de datos numpy\n",
    "X = np.array([np.array(i, dtype=\"object\") for i in A], dtype=\"object\")\n",
    "y = np.array([np.array(j, dtype=\"object\") for j in b], dtype=\"object\")\n",
    "\n",
    "print(X.shape)\n",
    "# forma basica general de las imagenes\n",
    "imgsh = X[0].shape\n",
    "# ajuste de forma para el modelo CNN\n",
    "X = X.reshape(fashion_df.shape[0], imgsh[0], imgsh[1], 1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d77100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semilla para el random\n",
    "rseed = 42\n",
    "# rseed = np.random.seed()\n",
    "\n",
    "# en tamanho de la muestra para pruebas esta entre 0.2 y 0.3\n",
    "train_pop = 0.8\n",
    "test_pop = 1.0 - train_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c2f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribuir los datos entre entrenamiento vs. pruebas\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=test_pop, random_state=rseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formateo para keras y tensorflow\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=\"float64\")\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=\"float64\")\n",
    "X_test = tf.convert_to_tensor(X_test, dtype=\"float64\")\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=\"float64\")\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2cab36",
   "metadata": {},
   "source": [
    "## Crear las bases para la GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22e9451",
   "metadata": {},
   "source": [
    "### Variables de Entrada y configuración de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfbdc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defino parametros necesarios para el modelo Autoencoder\n",
    "# parametros para las capas\n",
    "filters = 32    # 32, 64, 128\n",
    "# TODO cambiar el numero de neuronas de la capa intermedia\n",
    "# lat_neurons, v1 = 7*7, v2 = 28*28\n",
    "lat_neurons = 7*7\n",
    "\n",
    "# TODO cambiar la dimension del reshape convolucional\n",
    "# mid_reshape, v1 = (7, 7, 1), v2 = (28, 28, 1)\n",
    "mid_reshape = (7, 7, 1)\n",
    "ksize = (3, 3)\n",
    "\n",
    "# TODO cambiar el tamano del pool para reducir la imagen\n",
    "# psize, v1 = (2, 2), v2 = (1, 1)\n",
    "psize = (2, 2)\n",
    "\n",
    "# numero de categorias en la salida\n",
    "categories = len(label_names)\n",
    "# numero de neuronas en la capa de salida\n",
    "outn_gen = 1\n",
    "outn_dis = categories//categories\n",
    "\n",
    "# funcion de activacion para las capas convolucionales\n",
    "# otras opciones son: # \"relu\", \"LeakyReLU\"\n",
    "act = \"LeakyReLU\"\n",
    "# funcion de activacion para la capa de salida\n",
    "# otras opciones son: # \"sigmoid\", \"softmax\"\n",
    "out = \"sigmoid\"\n",
    "# padding para las capas convolucionales\n",
    "pad = \"same\"\n",
    "# porcentaje de dropout para imagenes\n",
    "ldrop_gen = 0.2\n",
    "ldrop_dis = 0.4\n",
    "\n",
    "# forma del kernel de entrada y de las capas intermedias\n",
    "inshape_gen = (lat_neurons)\n",
    "inshape_dis = X[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112cc83a",
   "metadata": {},
   "source": [
    "### Funciones de Ayuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d290a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    \"\"\"build_model crea un modelo secuencial de keras con las capas definidas.\n",
    "\n",
    "    Args:\n",
    "        layers (list[Layers]): lista de capas de tensorflow/keras.\n",
    "\n",
    "    Returns:\n",
    "        Model: modelo secuencial de keras.\n",
    "    \"\"\"    \n",
    "    # se crea el modelo secuencial\n",
    "    model = Sequential()\n",
    "    # se recorre la lista de capas\n",
    "    for layer in layers:\n",
    "        # se agrega la capa al modelo\n",
    "        model.add(layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0435f844",
   "metadata": {},
   "source": [
    "#### Capas del Generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8307178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definicion de las capas para el generador de imagenes\n",
    "gen_layer_lt = (\n",
    "    # capa de entrada\n",
    "    Input(shape=inshape_gen,\n",
    "          name=\"LayIn\"),\n",
    "\n",
    "    # capa intermedia densamente poblada con regularizacion\n",
    "    Dense(lat_neurons,\n",
    "          activation=act,\n",
    "          name=\"latentDense\"),\n",
    "    # capa intermedia de 1D a 2D\n",
    "    Reshape(mid_reshape,\n",
    "            name=\"layReshape\"),\n",
    "\n",
    "    # capa convolucional intermedia con regularizacion\n",
    "    Conv2D(int(filters/2),\n",
    "           ksize,\n",
    "           activation=act,\n",
    "           padding=pad,\n",
    "           name=\"DeConv1\"),\n",
    "    UpSampling2D(psize,\n",
    "                 name=\"DeUpsam1\"),\n",
    "    Dropout(ldrop_gen,\n",
    "            name=\"DeDrop1\"),\n",
    "\n",
    "    # capa convolucional intermedia con regularizacion\n",
    "    Conv2D(filters,\n",
    "           ksize,\n",
    "           activation=act,\n",
    "           padding=pad,\n",
    "           name=\"DeConv2\"),\n",
    "    UpSampling2D(psize,\n",
    "                 name=\"DeUpsam2\"),\n",
    "    Dropout(ldrop_gen,\n",
    "            name=\"DeDrop2\"),\n",
    "\n",
    "    # capa de salida\n",
    "    Conv2D(outn_gen,\n",
    "           ksize,\n",
    "           activation=out,\n",
    "           padding=pad,\n",
    "           name=\"LayOut\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da73034",
   "metadata": {},
   "source": [
    "#### Capas del Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae69f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definicion de las capas para el discriminador de imagenes\n",
    "dis_layer_lt = (\n",
    "    # capa de entrada\n",
    "    Input(shape=inshape_dis,\n",
    "          name=\"LayIn\"),\n",
    "\n",
    "    # capa convolucional intermedia con regularizacion\n",
    "    Conv2D(filters,\n",
    "           ksize,\n",
    "           activation=act,\n",
    "           padding=pad,\n",
    "           name=\"EnConv1\"),\n",
    "    MaxPooling2D(psize,\n",
    "                 padding=pad,\n",
    "                 name=\"EnPool1\"),\n",
    "    Dropout(ldrop_dis,\n",
    "            name=\"EnDrop1\"),\n",
    "\n",
    "    # capa convolucional intermedia con regularizacion\n",
    "    Conv2D(int(filters/2),\n",
    "           ksize,\n",
    "           activation=act,\n",
    "           padding=pad,\n",
    "           name=\"EnConv2\"),\n",
    "    MaxPooling2D(psize,\n",
    "                 padding=pad,\n",
    "                 name=\"EnPool2\"),\n",
    "    Dropout(ldrop_dis,\n",
    "            name=\"EnDrop2\"),\n",
    "\n",
    "    # capa intermedia de 2D a 1D\n",
    "    Flatten(name=\"LayFlat\"),\n",
    "    # capa intermedia densamente poblada con regularizacion\n",
    "    Dense(lat_neurons,\n",
    "          activation=act,\n",
    "          name=\"DenseMid\"),\n",
    "    Dropout(ldrop_dis,\n",
    "            name=\"MidDrop\"),\n",
    "\n",
    "#     # capa densa para clasificar los datos\n",
    "#     Dense(int(lat_neurons)//2,\n",
    "#           activation=act,\n",
    "#           name=\"ClsDense1\"),\n",
    "#     Dropout(ldrop_dis,\n",
    "#             name=\"ClsDrop1\"),\n",
    "\n",
    "#     # capa densa para clasificar los datos\n",
    "#     Dense(int(lat_neurons)//4,\n",
    "#           activation=act,\n",
    "#           name=\"ClsDense2\"),\n",
    "#     Dropout(ldrop_dis,\n",
    "#             name=\"ClsDrop2\"),\n",
    "\n",
    "    # capa de salida\n",
    "    Dense(outn_dis,\n",
    "          activation=out,\n",
    "          name=\"LayOut\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e32d9",
   "metadata": {},
   "source": [
    "#### Crear el Generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2deaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo el modelo del generador\n",
    "generator = build_model(gen_layer_lt)\n",
    "# reviso el modelo\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930fc105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimo imagen de la topologia del modelo\n",
    "wdir = os.getcwd()\n",
    "folder_models = \"Models\"\n",
    "model_fn = \"discws_gan_generator.png\"\n",
    "model_fp = os.path.join(folder_models, model_fn)\n",
    "print(\"La imagen del modelo esta en:\", model_fp)\n",
    "keras.utils.plot_model(generator,\n",
    "                       model_fp,\n",
    "                       show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# desplegando pruebas\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.figure(figsize=(20, 10))\n",
    "# Genera 10 imagenes con el modelo generador SIN ENTRENAR!\n",
    "latent_input = np.random.randn(categories, lat_neurons, 1)\n",
    "gen_img_lt = generator.predict(latent_input)\n",
    "\n",
    "for i, img in enumerate(gen_img_lt):\n",
    "    # imagen generada con el modelo\n",
    "    ax = plt.subplot(3, categories, i + 1)\n",
    "    temp_X = np.array(img)\n",
    "\n",
    "    # ajustar ty tamaño y color al original\n",
    "    plt.imshow(temp_X,\n",
    "               cmap=plt.cm.Spectral)\n",
    "    # imprimir el indice de la imagen\n",
    "    plt.xlabel(i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39910f89",
   "metadata": {},
   "source": [
    "#### Crear el Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72fecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_model(dis_layer_lt)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a947ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imprimo imagen de la topologia del modelo\n",
    "wdir = os.getcwd()\n",
    "folder_models = \"Models\"\n",
    "model_fn = \"discws_gan_discriminator.png\"\n",
    "model_fp = os.path.join(folder_models, model_fn)\n",
    "print(\"La imagen del modelo esta en:\", model_fp)\n",
    "keras.utils.plot_model(discriminator,\n",
    "                       model_fp,\n",
    "                       show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef579bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# desplegando pruebas\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.figure(figsize=(20, 10))\n",
    "# Genera 10 imagenes con el modelo discriminador SIN ENTRENAR!\n",
    "dis_img_lt = discriminator.predict(gen_img_lt)\n",
    "\n",
    "for i, label in enumerate(dis_img_lt):\n",
    "    # imagen generada con el modelo\n",
    "    ax = plt.subplot(3, categories, i + 1)\n",
    "    temp_X = np.array(gen_img_lt[i])\n",
    "\n",
    "    # ajustar ty tamaño y color al original\n",
    "    plt.imshow(temp_X,\n",
    "               cmap=plt.cm.Spectral)\n",
    "\n",
    "    # imprimir el nombre de la clase\n",
    "    idx = list(label).index(max(label))\n",
    "    # print(idx, label_names[idx])\n",
    "    # print(label_names)\n",
    "    plt.xlabel(label_names[idx])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd0fdca",
   "metadata": {},
   "source": [
    "## Crear Modelo GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa59a404",
   "metadata": {},
   "source": [
    "### Configurar funciones de perdida y optimizadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6609aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros de optimizacion del modelo\n",
    "# funcion de perdida\n",
    "# otras opciones son: \"BinaryCrossentropy\", \"CategoricalCrossentropy\"\n",
    "gen_loss = BinaryCrossentropy(from_logits=False,\n",
    "                              label_smoothing=0,\n",
    "                              name=\"gen_loss\")\n",
    "\n",
    "dis_loss = BinaryCrossentropy(from_logits=False,\n",
    "                              label_smoothing=0,\n",
    "                              name=\"dis_loss\")\n",
    "\n",
    "# metodo de optimizacion\n",
    "# otras opciones son: \"adam\", \"rmsprop\", \"sgd\"\n",
    "# otras opciones para el learning rate son:\n",
    "# para el generador: 0.001, 0.0001\n",
    "gen_lr = 0.0001\n",
    "# para el discriminador: 0.0001, 0.00001\n",
    "dis_lr = 0.00001\n",
    "gen_opti = Adam(learning_rate=gen_lr)\n",
    "dis_opti = Adam(learning_rate=dis_lr)\n",
    "opti = \"adam\"\n",
    "\n",
    "# metrica de evaluacion\n",
    "met = [\"accuracy\"]\n",
    "\n",
    "# parametros de la bitacora de entrenamiento del modelo, 1 es verbose\n",
    "ver = 1\n",
    "# numero de epocas\n",
    "epo = 30\n",
    "# tamano del lote de entrenamiento, se recomienda potencia de 2\n",
    "# otras opciones son: 32, 64, 128, 256\n",
    "bs = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf62575",
   "metadata": {},
   "source": [
    "### Crear Clase GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867772ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionGAN(Model):\n",
    "    def __init__(self, generator, discriminator, latent, *args, **kwargs):\n",
    "        \"\"\"__init__ inicializa la clase FashionGAN.\n",
    "\n",
    "        Args:\n",
    "            generator (Model): modelo keras/tensorflow del generador.\n",
    "            discriminator (Model): modelo keras/tensorflow del discriminador.\n",
    "            latent (int): configuracion del espacio latente para generar imagenes.\n",
    "        \"\"\"\n",
    "        # pasar cualquier argumento a la clase padre\n",
    "        super(FashionGAN, self).__init__(*args, **kwargs)\n",
    "\n",
    "        # crear el atributo para el espacio latente de entrada        \n",
    "        self.latent = latent\n",
    "        # crear los atributos para el generador y el discriminador\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "    \n",
    "    def compile(self,\n",
    "                gen_opti,\n",
    "                dis_opti,\n",
    "                gen_loss,\n",
    "                dis_loss,\n",
    "                *args,\n",
    "                **kwargs):\n",
    "        \"\"\"compile compilador de la clase FashionGAN que sigue las reglas de keras/tensorflow.\n",
    "\n",
    "        Args:\n",
    "            gen_opti (func): funcion de optimizacion para el generador.\n",
    "            dis_opti (func): funcion de optimizacion para el discriminador.\n",
    "            gen_loss (func): funcion de perdida para el generador.\n",
    "            dis_loss (func): funcion de perdida para el discriminador.\n",
    "        \"\"\"\n",
    "        # pasar cualquier argumento a la clase padre\n",
    "        super(FashionGAN, self).compile(*args, **kwargs)\n",
    "\n",
    "        # crear los atributos para el optimizador, la funcion de perdida y la metrica\n",
    "        self.gen_opti = gen_opti\n",
    "        self.dis_opti = dis_opti\n",
    "        self.gen_loss = gen_loss\n",
    "        self.dis_loss = dis_loss\n",
    "    \n",
    "    # def call(self, inputs, training=False):\n",
    "    #     \"\"\"call es el metodo que se ejecuta al llamar la clase FashionGAN.\n",
    "\n",
    "    #     Args:\n",
    "    #         inputs (ts): tensor de entrada.\n",
    "\n",
    "    #     Returns:\n",
    "    #         ts: tensor de salida.\n",
    "    #     \"\"\"\n",
    "    #     x = self.generator(inputs)\n",
    "    #     return self.discriminator(x)\n",
    "    \n",
    "    def train_step(self, batch):\n",
    "        \"\"\"train_step entrena el modelo FashionGAN. primero genera unas imagenes falsas y las pasa por el discriminador. Luego entrena el discriminador con las imagenes reales y falsas. Finalmente entrena el generador con las imagenes falsas.\n",
    "\n",
    "        Args:\n",
    "            batch (ts): batch de datos de entrenamiento.\n",
    "\n",
    "        Returns:\n",
    "            dict: valores de perdida del generador y del discriminador.\n",
    "        \"\"\"\n",
    "        # preparar datos de entrenamiento\n",
    "        real_img = batch\n",
    "        # OJO el tamanho del batch esta fijo a 128\n",
    "        latent_dims = (128, self.latent, 1)\n",
    "        # genero datos latentes para las imagenes\n",
    "        latent_input = tf.random.normal(latent_dims)\n",
    "        # genero imagenes segun el espacio latente\n",
    "        fake_img = self.generator(latent_input,\n",
    "                                  training=False)\n",
    "\n",
    "        # entrenar el discriminador\n",
    "        with tf.GradientTape() as dis_tape:\n",
    "            # crear conjunto con imagenes reales y falsas\n",
    "            # OJO no se porque necesita el idx [0]\n",
    "            X_real = self.discriminator(real_img[0],\n",
    "                                        training=True)\n",
    "            X_fake = self.discriminator(fake_img,\n",
    "                                        training=True)\n",
    "            # uno las imagenes falsas y reales en el mismo batch\n",
    "            X_real_fake = tf.concat([X_real, X_fake],\n",
    "                                    axis=0)\n",
    "\n",
    "            # crear conjunto con etiquetas reales y falsas\n",
    "            y_real_fake = tf.concat([tf.zeros_like(X_real),\n",
    "                                     tf.ones_like(X_fake)],\n",
    "                                    axis=0)\n",
    "\n",
    "            # agregar ruido a las etiquetas para no sobre ajustar\n",
    "            noise_real = 0.15*tf.random.uniform(tf.shape(X_real))\n",
    "            noise_fake = -0.15*tf.random.uniform(tf.shape(X_fake))\n",
    "            # le sumo el ruido generado a las etiquetas\n",
    "            y_real_fake += tf.concat([noise_real,\n",
    "                                      noise_fake],\n",
    "                                     axis=0)\n",
    "\n",
    "            # calcular la perdida del discriminador\n",
    "            total_dis_loss = self.dis_loss(y_real_fake,\n",
    "                                           X_real_fake)\n",
    "\n",
    "        # calcular los gradientes del discriminador\n",
    "        dis_train_vars = self.discriminator.trainable_variables\n",
    "        dis_grads = dis_tape.gradient(total_dis_loss,\n",
    "                                      dis_train_vars)\n",
    "        # aqui aprende el discriminadoer\n",
    "        self.dis_opti.apply_gradients(zip(dis_grads,\n",
    "                                          dis_train_vars))\n",
    "\n",
    "        # entrenar el generador\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            # crear imagenes falsas\n",
    "            gen_img = self.generator(latent_input,\n",
    "                                     training=True)\n",
    "            # pasa las imagenes falsas por el discriminador\n",
    "            predict_labels = self.discriminator(gen_img,\n",
    "                                                training=False)\n",
    "            # calcular la perdida del generador\n",
    "            # OJO el generador mejora si engaña al discriminador\n",
    "            total_gen_loss = self.gen_loss(tf.zeros_like(predict_labels),\n",
    "                                           predict_labels)\n",
    "\n",
    "        # calcular los gradientes del generador\n",
    "        gen_train_vars = self.generator.trainable_variables\n",
    "        gen_grads = gen_tape.gradient(total_gen_loss,\n",
    "                                      gen_train_vars)\n",
    "        # aqui aprende el generador\n",
    "        self.gen_opti.apply_gradients(zip(gen_grads,\n",
    "                                          gen_train_vars))\n",
    "        # calculando la perdida total de la GAN\n",
    "        total_gan_loss = 0.5*(total_gen_loss + total_dis_loss)\n",
    "        total_loss = {\"gen_loss\": total_gen_loss,\n",
    "                      \"dis_loss\": total_dis_loss,\n",
    "                      \"gan_loss\": total_gan_loss}\n",
    "\n",
    "        # retornar las perdidas del generador y del discriminador\n",
    "        return total_loss\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        \"\"\"test_step tests the model FashionGAN. It generates some fake images and passes them through the discriminator. Then it evaluates the discriminator with the real and fake images.\n",
    "\n",
    "        Args:\n",
    "            batch (ts): batch of test data.\n",
    "\n",
    "        Returns:\n",
    "            dict: loss values of the generator and the discriminator.\n",
    "        \"\"\"\n",
    "        # prepare test data\n",
    "        real_img = batch\n",
    "        # OJO the batch size is fixed to 128\n",
    "        latent_dims = (128, self.latent, 1)\n",
    "        # generate latent data for the images\n",
    "        latent_input = tf.random.normal(latent_dims)\n",
    "        # generate images according to the latent space\n",
    "        fake_img = self.generator(latent_input,\n",
    "                                  training=False)\n",
    "\n",
    "        # evaluate the discriminator\n",
    "        X_real = self.discriminator(real_img[0],\n",
    "                                    training=False)\n",
    "        X_fake = self.discriminator(fake_img,\n",
    "                                    training=False)\n",
    "        # combine the fake and real images in the same batch\n",
    "        X_real_fake = tf.concat([X_real, X_fake], axis=0)\n",
    "\n",
    "        # create a set with real and fake labels\n",
    "        y_real_fake = tf.concat([tf.zeros_like(X_real), tf.ones_like(X_fake)], axis=0)\n",
    "\n",
    "        # calculate the discriminator's loss\n",
    "        total_dis_loss = self.dis_loss(y_real_fake, X_real_fake)\n",
    "\n",
    "        # evaluate the generator\n",
    "        gen_img = self.generator(latent_input,\n",
    "                                 training=False)\n",
    "        # pass the fake images through the discriminator\n",
    "        predict_labels = self.discriminator(gen_img,\n",
    "                                            training=False)\n",
    "        # calculate the generator's loss\n",
    "        total_gen_loss = self.gen_loss(tf.zeros_like(predict_labels),\n",
    "                                       predict_labels)\n",
    "\n",
    "        # calculating the total GAN loss\n",
    "        total_gan_loss = 0.5 * (total_gen_loss + total_dis_loss)\n",
    "        total_loss = {\"gen_loss\": total_gen_loss,\n",
    "                      \"dis_loss\": total_dis_loss,\n",
    "                      \"gan_loss\": total_gan_loss}\n",
    "\n",
    "        # return the generator's and discriminator's losses\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce0d50b",
   "metadata": {},
   "source": [
    "### Crear Clase para paradas tempranas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(Callback):\n",
    "    \"\"\"GANMonitor clase para monitoreal el proceso de entrenamiento del modelo FashionGAN.\n",
    "\n",
    "    Args:\n",
    "        Callback (class): clase de keras/tensorflow para monitorear el entrenamiento de un modelo e implementar acciones personalizadas en diferentes etapas del entrenamiento.\n",
    "    \"\"\"    \n",
    "    def __init__(self,\n",
    "                 num_img=3,\n",
    "                 latent_dim=latent_input,\n",
    "                 img_f=\"Images\"):\n",
    "        \"\"\"__init__ funcion de inicializacion de la clase GANMonitor. Crea un monitor para el modelo FashionGAN.\n",
    "\n",
    "        Args:\n",
    "            num_img (int, optional): numero de imagenes a generar. Por defecto 3.\n",
    "            latent_dim (int, optional): tamano del espacio latente. Por defecto latent_input.\n",
    "            img_f (str, optional): folder para guardar las imagenes generadas. Por defecto \"Images\".\n",
    "        \"\"\"\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.img_f = img_f\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"on_epoch_end funcion personalizada para monitorear el proceso de entrenamiento del modelo FashionGAN. Crea imagenes generadas por el modelo al terminar esa epoca de entrenamiento.\n",
    "\n",
    "        Args:\n",
    "            epoch (int): epoca de entrenamiento.\n",
    "            logs (class, optional): bitacora de entrenamiento. Por defecto None.\n",
    "        \"\"\"\n",
    "        # genera un espacio latente segun el numero de imagenes\n",
    "        rand_latent_vec = tf.random.uniform((self.num_img,\n",
    "                                             self.latent_dim, 1))\n",
    "        # genera imagenes segun el espacio latente\n",
    "        gen_img = self.model.generator(rand_latent_vec)\n",
    "        # deja los pixeles con valores entre 0 y 255\n",
    "        gen_img *= 255\n",
    "        # transforma las imagenes a formato de imagen\n",
    "        gen_img.numpy()\n",
    "        # guarda las imagenes en el folder adecuado\n",
    "        for i in range(self.num_img):\n",
    "            img = array_to_img(gen_img[i])\n",
    "            # crear folder de la epoca\n",
    "            ef = f\"epoch_{epoch+1}\"\n",
    "            if not os.path.exists(os.path.join(self.img_f, ef)):\n",
    "                os.makedirs(os.path.join(self.img_f, ef))\n",
    "            fp = f\"gen_img_{i+1}.png\"\n",
    "            img.save(os.path.join(self.img_f, ef, fp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbceaae",
   "metadata": {},
   "source": [
    "### Entrenar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d303d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea una instancia de la clase FashionGAN\n",
    "gan_fash_model = FashionGAN(generator, discriminator, inshape_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a956a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compila el modelo con los parametros de optimizacion\n",
    "gan_fash_model.compile(gen_opti=gen_opti,\n",
    "                       dis_opti=dis_opti,\n",
    "                       gen_loss=gen_loss,\n",
    "                       dis_loss=dis_loss)\n",
    "\n",
    "# configura el monitor de entrenamiento\n",
    "gan_monitor = GANMonitor(num_img=3,\n",
    "                         latent_dim=lat_neurons,\n",
    "                         img_f=\"Images\")\n",
    "\n",
    "# configura la parada temprana\n",
    "gan_earlystop_loss = EarlyStopping(monitor=\"gen_loss\",\n",
    "                                   min_delta=0.0001,\n",
    "                                   patience=5,    # recomendado 100 epocas\n",
    "                                   verbose=ver,\n",
    "                                   mode=\"min\",\n",
    "                                   restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56701bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# se recomienda minimo 2000 epochs\n",
    "fashion_logs = gan_fash_model.fit(x=X_train,\n",
    "                                  y=y_train,\n",
    "                                  batch_size=bs,\n",
    "                                  epochs=epo,\n",
    "                                  verbose=ver,\n",
    "                                  callbacks=[gan_monitor,\n",
    "                                             gan_earlystop_loss],\n",
    "                                  validation_data=(X_test, y_test),\n",
    "                                  workers=8,\n",
    "                                  shuffle=False,\n",
    "                                  use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec3859",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Loss')\n",
    "plt.plot(fashion_logs.history['dis_loss'], label='d_loss')\n",
    "plt.plot(fashion_logs.history['gen_loss'], label='g_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057de6ac",
   "metadata": {},
   "source": [
    "## Probar Modelo GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9fc5a4",
   "metadata": {},
   "source": [
    "### Generar Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63438ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = generator.predict(tf.random.normal((16, lat_neurons, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b494cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(ncols=4, nrows=4, figsize=(10, 10))\n",
    "for r in range(4):\n",
    "    for c in range(4):\n",
    "        ax[r][c].imshow(imgs[(r+1)*(c+1)-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff25ea8",
   "metadata": {},
   "source": [
    "### Guardar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7802d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af976c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar los modelos, discrinador y generador\n",
    "wdir = os.getcwd()\n",
    "folder_models = \"Models\"\n",
    "gen_model_fn = \"discws_fashion_gan_gen.h5\"\n",
    "dis_model_fn = \"discws_fashion_gan_dis.h5\"\n",
    "# tf.keras.models.save_model(cnn_autoencoder, model_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d0a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardando generador\n",
    "model_fp = os.path.join(folder_models, gen_model_fn)\n",
    "print(\"El generador entrenado esta en:\", model_fp)\n",
    "generator.save(model_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0972f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardando discriminador\n",
    "model_fp = os.path.join(folder_models, dis_model_fn)\n",
    "print(\"El discriminador entrenado esta en:\", model_fp)\n",
    "discriminator.save(model_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee92c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow tensorflow-gpu matplotlib tensorflow-datasets ipywidgets\n",
    "# !pip list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84be907-35e2-43db-a645-b6b164302aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing in tensorflow\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [
    "206ba81f-978a-4c31-9c3d-6ebe5a5bfc29"
   ],
   "name": "FashionGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
